{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "def get_session(gpu_fraction=0.2):\n",
    "    \n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)\n",
    "\n",
    "    if num_threads:\n",
    "        return tf.Session(config=tf.ConfigProto(\n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))\n",
    "    else:\n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "KTF.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def getConnection_c2v(H):   # using r edges of a variable node to calculate the j edge\n",
    "    IndexMatrix=np.zeros(H.shape,dtype=int)\n",
    "    dim=np.sum(H,dtype=int)\n",
    "    C_c2v=np.zeros((dim,dim),dtype=bool)\n",
    "    onesPosition=[]\n",
    "    otherOnesPosition=[]\n",
    "    onesIndex=-1\n",
    "     \n",
    "    for j in range(0,H.shape[1]):\n",
    "        for i in range(0,H.shape[0]):\n",
    "            if H[i,j]==1:\n",
    "                onesIndex+=1\n",
    "                onesPosition.append(onesIndex)\n",
    "                \n",
    "        for k in onesPosition:\n",
    "            otherOnesPosition=list(onesPosition)\n",
    "            otherOnesPosition.remove(k)\n",
    "#             print('onesPosition:',onesPosition)\n",
    "#             print('otheronesposition:', otherOnesPosition)\n",
    "            for l in otherOnesPosition:\n",
    "                C_c2v[l,k]=True\n",
    "            otherOnesPosition=[]\n",
    "        onesPosition=[]\n",
    "#         print('cleared')\n",
    "#         print(onesPosition)\n",
    "        \n",
    "    return C_c2v\n",
    "\n",
    "def getConnection_v2c(H): ## using j edges of a check node to calculate the r edge\n",
    "    IndexMatrix=np.zeros(H.shape,dtype=int)\n",
    "    dim=np.sum(H,dtype=int)\n",
    "    C_v2c=np.zeros((dim,dim),dtype=bool)\n",
    "    onesPosition=[]\n",
    "    otherOnesPosition=[]\n",
    "    onesIndex=-1\n",
    "    \n",
    "    for j in range(0,H.shape[1]):   # set index for ones in H\n",
    "        for i in range(0,H.shape[0]):\n",
    "            if H[i,j]==1:\n",
    "                onesIndex+=1\n",
    "                IndexMatrix[i,j]=onesIndex\n",
    "                             \n",
    "    for i in range(0,H.shape[0]):\n",
    "        for j in range(0,H.shape[1]):\n",
    "            if H[i,j]==1:   \n",
    "               onesPosition.append(IndexMatrix[i,j]) \n",
    "            \n",
    "        for k in onesPosition:\n",
    "            otherOnesPosition=list(onesPosition)\n",
    "            otherOnesPosition.remove(k)\n",
    "#             print('onesPosition:',onesPosition)\n",
    "#             print('otheronesposition:', otherOnesPosition)\n",
    "            for l in otherOnesPosition:\n",
    "                C_v2c[l,k]=True\n",
    "            otherOnesPosition=[]\n",
    "        onesPosition=[]\n",
    "#         print('cleared')\n",
    "#         print(onesPosition)\n",
    "    return C_v2c\n",
    "\n",
    "\n",
    "\n",
    "# there are mistakes!!!!\n",
    "#\n",
    "# def getConnection_for_firstLayer(H): #the dimention of C_firstLayer is number of variable nodes x  number of edges\n",
    "#                                      # from the channel level to calulate the r edge from a check node\n",
    "#     IndexMatrix=np.zeros(H.shape,dtype=int)\n",
    "#     dim=np.sum(H,dtype=int)\n",
    "#     C_firstLayer=np.zeros((H.shape[1],dim),dtype=bool)\n",
    "#     onesIndex=-1\n",
    "    \n",
    "#     for j in range(0,H.shape[1]):   # set index for ones in H\n",
    "#         for i in range(0,H.shape[0]):\n",
    "#             if H[i,j]==1:\n",
    "#                 onesIndex+=1\n",
    "#                 IndexMatrix[i,j]=onesIndex\n",
    "                             \n",
    "#     for i in range(0,H.shape[0]):\n",
    "#         for j in range(0,H.shape[1]):\n",
    "#             if H[i,j]==1:\n",
    "#                 for k in range(0,H.shape[0]):\n",
    "#                     if k!=i:\n",
    "#                         if H[k,j]==1:\n",
    "#                            C_firstLayer[i,IndexMatrix[i,j]]=True\n",
    "#                            break;\n",
    "            \n",
    "#     return C_firstLayer\n",
    "\n",
    "def getConnection_for_firstLayer(H): #the dimention of C_firstLayer is number of variable nodes x  number of edges\n",
    "                                     # from the channel level to calulate the r edge from a check node\n",
    "    IndexMatrix=np.zeros(H.shape,dtype=int)\n",
    "    dim=np.sum(H,dtype=int)\n",
    "    C_firstLayer=np.zeros((H.shape[1],dim),dtype=bool)\n",
    "    onesIndex=-1\n",
    "    \n",
    "    for j in range(0,H.shape[1]):   # set index for ones in H\n",
    "        for i in range(0,H.shape[0]):\n",
    "            if H[i,j]==1:\n",
    "                onesIndex+=1\n",
    "                C_firstLayer[j,onesIndex]=True\n",
    "                             \n",
    "            \n",
    "    return C_firstLayer\n",
    "\n",
    "\n",
    "\n",
    "def getConnection_for_lastLayer(H): #the dimention of C_lastLayer is number of number of edges x variable nodes\n",
    "                                     \n",
    "    IndexMatrix=np.zeros(H.shape,dtype=int)\n",
    "    dim=np.sum(H,dtype=int)\n",
    "    C_lastLayer=np.zeros((dim,H.shape[1]),dtype=bool)\n",
    "    onesIndex=-1\n",
    "    \n",
    "    for j in range(0,H.shape[1]):   # set index for ones in H\n",
    "        for i in range(0,H.shape[0]):\n",
    "            if H[i,j]==1:\n",
    "                onesIndex+=1\n",
    "                C_lastLayer[onesIndex,j]=True\n",
    "            \n",
    "    return C_lastLayer\n",
    "\n",
    "\n",
    "# if a weigt is initialized to zero, \n",
    "#in future iterations it will not be updated by gradient descent and backpropagation\n",
    "\n",
    "# def init_for_v2c_layer(shape,dtype=None):\n",
    "#     print(shape)\n",
    "#     #matrix=getConnection_v2c(H)\n",
    "#     matrix=C_v2c\n",
    "#     matrix=tf.convert_to_tensor(matrix,dtype=tf.float32)\n",
    "#     result_matrix=tf.random_normal(shape, dtype=tf.float32)\n",
    "#     return tf.multiply(result_matrix,matrix)\n",
    "\n",
    "\n",
    "def init_for_r2q_layer(shape,dtype=None):\n",
    "#     print('shape: ',shape)\n",
    "    #matrix=getConnection_c2v(H)  #not need to call the function, a matrix can be globle.\n",
    "    matrix=C_r2q\n",
    "    matrix=tf.convert_to_tensor(matrix,dtype=tf.float32)\n",
    "    #result_matrix=tf.random_normal(shape, dtype=tf.float32)\n",
    "    result_matrix=tf.ones(shape,dtype=tf.float32)\n",
    "    return tf.multiply(result_matrix,matrix)\n",
    "\n",
    "\n",
    "def init_for_firstLayer(shape,dtype=None):\n",
    "#     print('shape_firstLayer: ',shape)\n",
    "    matrix=C_firstLayer\n",
    "    matrix=tf.convert_to_tensor(matrix,dtype=tf.float32)\n",
    "    #result_matrix=tf.random_normal(shape, dtype=tf.float32)\n",
    "    result_matrix=tf.ones(shape,dtype=tf.float32)\n",
    "    return tf.multiply(result_matrix,matrix)\n",
    "\n",
    "\n",
    "def init_for_lastLayer(shape,dtype=None):\n",
    "    matrix=C_lastLayer\n",
    "    matrix=tf.convert_to_tensor(matrix,dtype=tf.float32)\n",
    "    #result_matrix=tf.random_normal(shape, dtype=tf.float32)\n",
    "    result_matrix=tf.ones(shape,dtype=tf.float32)\n",
    "    return tf.multiply(result_matrix,matrix)\n",
    "\n",
    "\n",
    "def get_r_edges_tensorflow(x,q2r_matrix):\n",
    "    v2c_matrix=tf.convert_to_tensor(q2r_matrix,dtype=tf.float32)\n",
    "    v2c_zeros_matrix=tf.zeros(tf.shape(v2c_matrix),dtype=tf.float32)\n",
    "    v2c_zeros_matrix=tf.equal(v2c_zeros_matrix,tf.transpose(v2c_matrix))\n",
    "    v2c_zeros_matrix=tf.cast(v2c_zeros_matrix,tf.float32)\n",
    "    \n",
    "    x1=tf.abs(x)                              #avoid to be zero\n",
    "#     x1=tf.log(tf.div((tf.exp(x1)+1),(tf.exp(x1)-1)))\n",
    "#     x1=tf.matmul(x1,v2c_matrix)                      # x1*v2c_matrix\n",
    "#     x1=tf.log(tf.div((tf.exp(x1)+1),(tf.exp(x1)-1)))\n",
    "\n",
    "    x1=-tf.log(tf.tanh(x1/2))\n",
    "    x1=tf.matmul(x1,v2c_matrix) \n",
    "    x1=-tf.log(tf.tanh(x1/2))\n",
    "    \n",
    "    x2=tf.sign(x)                             \n",
    "    x2_zeros=tf.zeros(tf.shape(x),dtype=tf.float32)     #avoid to be zero  make sign(0) to be 1\n",
    "    x2_zeros=tf.cast(tf.equal(x2_zeros,x2),tf.float32)\n",
    "    x2=x2+x2_zeros\n",
    "    \n",
    "#     print('x2_befor_expand_dims: ',x2)\n",
    "    x2=tf.expand_dims(x2,1)\n",
    "    \n",
    "#     print('x2_after_expand_dims: ',x2)\n",
    "    \n",
    "    x2=tf.multiply(x2,tf.transpose(v2c_matrix))+tf.transpose(v2c_zeros_matrix)# should add a matrix with shape(?,n,n)\n",
    "                                                                         # tf.add supports broadcasting\n",
    "    x2=tf.transpose(x2,perm=[0, 2, 1])\n",
    "#     print('v2c_zeros_matrix: ',v2c_zeros_matrix)\n",
    "#     print('x2: ',x2)\n",
    "    \n",
    "    x2=tf.reduce_prod(x2,1) #shape from (?,64) to (1,64) caused error\n",
    "#     print('x2_prod: ',x2)\n",
    "    \n",
    "    return tf.minimum(tf.maximum(tf.multiply(x1,x2),-20),20)\n",
    "\n",
    "\n",
    "\n",
    "# transform the form of edges-messages matrix\n",
    "def transform_edges_matrix_to_vector(H,matrix):\n",
    "    vector=[]\n",
    "    for j in range(H.shape[1]):\n",
    "        for i in range(H.shape[0]):\n",
    "            if H[i,j]==1:\n",
    "                vector.append(matrix[i,j])\n",
    "    return np.array(vector,dtype=float)\n",
    "\n",
    "def addNoise(x, sigma):\n",
    "    w = sigma*tf.random_normal(tf.shape(x))\n",
    "    return x + w\n",
    "\n",
    "# def ber(y_true, y_pred):\n",
    "#     #return K.mean(K.not_equal(y_true, K.round(y_pred)))\\n\",\n",
    "#     return tf.reduce_mean(tf.cast(tf.not_equal(y_true, tf.round(y_pred)),tf.float32))\n",
    "\n",
    "def BLER_errors(y_true,y_pred):\n",
    "    c=tf.reduce_sum(tf.cast(tf.not_equal(y_true, tf.round(y_pred)),tf.float32),1)\n",
    "    c=tf.cast(c,tf.bool)\n",
    "    c=tf.reduce_sum(tf.cast(c,tf.float32))\n",
    "    return tf.reduce_sum(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ldpc\n",
    "# mat_contents = sio.loadmat('mat_files/ldpcH_20x40')\n",
    "# H = mat_contents['H'].toarray()   #load mat file,and convert it to numpy ndarray\n",
    "# H=H.astype(int)\n",
    "\n",
    "#polar codes\n",
    "mat_contents = sio.loadmat('mat_files/H_Polarcodes_32x64_for_allZeros.mat')\n",
    "H = mat_contents['H']   #load mat file,and convert it to numpy ndarray\n",
    "H=H.astype(int)\n",
    "\n",
    "# H=np.array([[1,1,1,0,1,1],[0,1,0,1,1,0],[0,1,1,1,0,1]],dtype=int)\n",
    "# mat_contents = sio.loadmat('result')\n",
    "# result = mat_contents['result']   #load mat file,and convert it to numpy ndarray\n",
    "# mat_contents = sio.loadmat('H')\n",
    "# H=mat_contents['H'].toarray()\n",
    "# H=H.astype(int)\n",
    "# mat_contents = sio.loadmat('testset')\n",
    "# x_train=mat_contents['Lc']\n",
    "\n",
    "n_iteration=6\n",
    "\n",
    "\n",
    "edges_count=np.sum(H,dtype=int)\n",
    "input_shape=H.shape[1]\n",
    "train_sigma=0.6\n",
    "n_epochs=200\n",
    "C_firstLayer=getConnection_for_firstLayer(H)\n",
    "C_q2r=getConnection_v2c(H)\n",
    "C_r2q=getConnection_c2v(H)\n",
    "C_r2q=np.concatenate((C_firstLayer, C_r2q), axis=0)\n",
    "C_lastLayer=getConnection_for_lastLayer(H)\n",
    "C_lastLayer=np.concatenate((np.eye(input_shape,dtype=bool), C_lastLayer), axis=0)\n",
    "weights_count=np.sum(C_q2r)\n",
    "weights_count_outputlayer=np.sum(C_lastLayer)\n",
    "sigma=0.6\n",
    "\n",
    "y_train=np.zeros((1280,input_shape),dtype=float)\n",
    "# y_train=np.array([y_train])\n",
    "x_train=np.ones((1280,input_shape),dtype=float)\n",
    "# x_train=x_train+sigma_ch*np.random.randn(40)\n",
    "# x_train=np.array([x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"output/concat_62:0\", shape=(?, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#build graph\n",
    "\n",
    "exec('x = tf.placeholder(tf.float32, shape=[None, {}])'.format(input_shape))\n",
    "exec('y_ = tf.placeholder(tf.float32, shape=[None, {}])'.format(input_shape))\n",
    "\n",
    "C_firstLayer=tf.constant(C_firstLayer,dtype=tf.float32)\n",
    "for i in range(n_iteration):\n",
    "    exec('weights_layer_r2q_{}'.format(i)+'={}')\n",
    "    \n",
    "x_noise=addNoise(x,sigma)\n",
    "q_0=tf.minimum(tf.maximum(tf.matmul(x_noise,C_firstLayer),-20),20)\n",
    "r_0=get_r_edges_tensorflow(q_0,C_q2r)\n",
    "r_0=tf.concat([x_noise,r_0],1)\n",
    "\n",
    "for i in range(1,n_iteration):\n",
    "    with tf.name_scope('layer_r2q_{}'.format(i)):\n",
    "        for j in range(weights_count):\n",
    "            exec('layer_r2q_{}_w{}=tf.Variable(tf.truncated_normal([1,1]),name=\\'w{}\\')'.format(i,j,j))\n",
    "        j=0\n",
    "        for k in range(C_r2q.shape[1]):\n",
    "            nonzero_indices=np.where(C_r2q[:,k]!=0)[0]\n",
    "            if nonzero_indices.shape[0] !=0:\n",
    "                exec('layer{}_q{}=layer_r2q_{}_w{}*tf.expand_dims(r_{}[:,nonzero_indices[0]],1)'\n",
    "                     .format(i,k,i,j,i-1))\n",
    "                exec('layer{}_q{}=tf.minimum(tf.maximum(layer{}_q{},-20),20)'.format(i,k,i,k))\n",
    "                j+=1\n",
    "                if nonzero_indices.shape[0] !=1:\n",
    "                    for l in range(1,nonzero_indices.shape[0]):\n",
    "                        exec('layer{}_q{}=layer{}_q{}+layer_r2q_{}_w{}*tf.expand_dims(r_{}[:,nonzero_indices[{}]],1)'\n",
    "                             .format(i,k,i,k,i,j,i-1,l))\n",
    "                        j+=1\n",
    "                exec('layer{}_q{}=tf.minimum(tf.maximum(layer{}_q{},-20),20)'.format(i,k,i,k))\n",
    "                \n",
    "        exec('q_{}=tf.concat([layer{}_q{},layer{}_q{}],1)'.format(i,i,0,i,1))\n",
    "        for k in range(2,C_r2q.shape[1]):\n",
    "            exec('q_{}=tf.concat([q_{},layer{}_q{}],1)'.format(i,i,i,k))\n",
    "\n",
    "    with tf.name_scope('layer_q2r_{}'.format(i)):\n",
    "        exec('r_{}=tf.concat([x_noise,get_r_edges_tensorflow(q_{},C_q2r)],1)'\n",
    "             .format(i,i))\n",
    "                    \n",
    "with tf.name_scope('output'):\n",
    "    outputLayer_weights={}\n",
    "    for j in range(weights_count_outputlayer):\n",
    "        exec('outputLayer_w{}=tf.Variable(tf.truncated_normal([1,1]),name=\\'w{}\\')'.format(j,j))\n",
    "    \n",
    "    j=0\n",
    "    for k in range(C_lastLayer.shape[1]):\n",
    "        nonzero_indices=np.where(C_lastLayer[:,k]!=0)[0]\n",
    "        if nonzero_indices.shape[0] !=0:\n",
    "#             exec('output{}=tf.sigmoid(-1*outputLayer_w{}*tf.expand_dims(r_{}[:,nonzero_indices[0]],1))'\n",
    "#                  .format(k,j,n_iteration-1))\n",
    "#             this is false. should be first added,then sigmoid()\n",
    "            exec('output{}=outputLayer_w{}*tf.expand_dims(r_{}[:,nonzero_indices[0]],1)'\n",
    "                  .format(k,j,n_iteration-1))\n",
    "\n",
    "            j+=1\n",
    "            if nonzero_indices.shape[0] !=1:\n",
    "                for l in range(1,nonzero_indices.shape[0]):\n",
    "#                     exec('output{}=output{}+tf.sigmoid(-1*outputLayer_w{}*tf.expand_dims(r_{}[:,nonzero_indices[{}]],1))'\n",
    "#                          .format(k,k,j,n_iteration-1,l))\n",
    "                    exec('output{}=output{}+outputLayer_w{}*tf.expand_dims(r_{}[:,nonzero_indices[{}]],1)'\n",
    "                         .format(k,k,j,n_iteration-1,l))\n",
    "                    j+=1\n",
    "            exec('output{}=tf.sigmoid(-1*output{})'.format(k,k))\n",
    "    exec('y=tf.concat([output{},output{}],1)'.format(0,1))\n",
    "    for k in range(2,C_lastLayer.shape[1]):\n",
    "        exec('y=tf.concat([y,output{}],1)'.format(k))\n",
    "    print(y)\n",
    "\n",
    "\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71360"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#check paper Nachmani - lerning to decode linear codes using deep learning\n",
    "learning_rate=tf.placeholder(tf.float32,shape=[])\n",
    "loss_value=tf.reduce_mean(tf.losses.mean_squared_error(labels=y_,predictions=y))\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_value)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.round(y),tf.round(y_)),tf.float32))\n",
    "ber=tf.reduce_mean(tf.cast(tf.not_equal(y_, tf.round(y)),tf.float32))\n",
    "BLER=BLER_errors(y_,y)\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     sess.graph.finalize()\n",
    "#     for i in range(1000):\n",
    "# #         for j in range(10):\n",
    "# #             train_step.run(feed_dict={x:x_train[128*j:128*(j+1)],y_:y_train[128*j:128*(j+1)]})\n",
    "        \n",
    "#         train_step.run(feed_dict={x:x_train[0:32],y_:y_train[0:32]})\n",
    "#         print('loss_value_{}: '.format(i),loss_value.eval({x:x_train[0:50,:],y_:y_train[0:50,:]}))\n",
    "#         print('accuracy_{}: '.format(i),accuracy.eval({x:x_train[0:50,:],y_:y_train[0:50,:]}))\n",
    "#         print('ber_{}: '.format(i),ber.eval({x:x_train[0:50,:],y_:y_train[0:50,:]}))\n",
    "#         print('BLER_{}: '.format(i),BLER.eval({x:x_train[0:50,:],y_:y_train[0:50,:]}))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.graph.finalize()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "    for i in range(1000):\n",
    "    #         for j in range(10):\n",
    "    #             train_step.run(feed_dict={x:x_train[128*j:128*(j+1)],y_:y_train[128*j:128*(j+1)]})\n",
    "        if i<500:\n",
    "            train_step.run(feed_dict={x:x_train[0:128,:],y_:y_train[0:128,:],learning_rate:0.7})\n",
    "            print('loss_value_{}: '.format(i),loss_value.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "            print('accuracy_{}: '.format(i),accuracy.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "            print('ber_{}: '.format(i),ber.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "            print('BLER_{}: '.format(i),BLER.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "        elif i<800:\n",
    "            train_step.run(feed_dict={x:x_train[0:128,:],y_:y_train[0:128,:],learning_rate:0.5})\n",
    "            print('loss_value_{}: '.format(i),loss_value.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "            print('accuracy_{}: '.format(i),accuracy.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "            print('ber_{}: '.format(i),ber.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "            print('BLER_{}: '.format(i),BLER.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))   \n",
    "        else:\n",
    "            train_step.run(feed_dict={x:x_train[0:128,:],y_:y_train[0:128,:],learning_rate:0.3})\n",
    "            print('loss_value_{}: '.format(i),loss_value.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "            print('accuracy_{}: '.format(i),accuracy.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "            print('ber_{}: '.format(i),ber.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))\n",
    "            print('BLER_{}: '.format(i),BLER.eval({x:x_train[0:128,:],y_:y_train[0:128,:]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with sess.as_default():\n",
    "#     output0=output0.eval({x:[x_train[0,:]]})\n",
    "#     output1=output1.eval({x:[x_train[0,:]]})\n",
    "    y_predict=y.eval({x:[x_train[0,:]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4b913d602d9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test_temp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msigmas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcode_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             temp=temp+ber.eval({x_test_temp[j*test_batch:(j+1)*test_batch],\n\u001b[0m\u001b[1;32m     30\u001b[0m                                y_test_temp[j*test_batch:(j+1)*test_batch]})\n\u001b[1;32m     31\u001b[0m         \u001b[0mber\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "code_length=input_shape\n",
    "info_rate=0.5\n",
    "test_batch = 128  \n",
    "num_words = 1000      # multiple of test_batch\n",
    "\n",
    "x_test_temp=np.ones((num_words,code_length),dtype=float)\n",
    "y_test=np.zeros((num_words,code_length),dtype=float)\n",
    "\n",
    "# for i in range(num_words):\n",
    "#     x_test_temp[i,:]=x\n",
    "#     y_test[i,:]=y\n",
    "\n",
    "\n",
    "SNR_dB_start_Eb = 0\n",
    "SNR_dB_stop_Eb = 5\n",
    "SNR_points = 20\n",
    "SNR_dB_start_Es = SNR_dB_start_Eb + 10*np.log10(info_rate)\n",
    "SNR_dB_stop_Es = SNR_dB_stop_Eb + 10*np.log10(info_rate)\n",
    "sigma_start = np.sqrt(1/(2*10**(SNR_dB_start_Es/10)))\n",
    "sigma_stop = np.sqrt(1/(2*10**(SNR_dB_stop_Es/10)))\n",
    "sigmas = np.linspace(sigma_start, sigma_stop, SNR_points)\n",
    "ber_result=np.zeros(len(sigmas),dtype=float)\n",
    "temp=0\n",
    "\n",
    "with sess.as_default():\n",
    "    for i in range(len(sigmas)):\n",
    "        x_test=x_test_temp+sigmas[i]*np.random.normal(0,1,(num_words,code_length))\n",
    "        for j in range((np.floor(num_words/test_batch)).astype(int)):\n",
    "            temp=temp+ ber.eval({x_test_temp[j*test_batch:(j+1)*test_batch],\n",
    "                               y_test_temp[j*test_batch:(j+1)*test_batch]})\n",
    "        ber_result[i]=temp/(j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "try1=np.array([1,0,1,1,0,0,0,1],dtype=float)\n",
    "np.where(try1!=0)[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_lastLayer.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_c=np.array(range(10)).convert_to_tensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(100/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(num_words/test_batch).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
